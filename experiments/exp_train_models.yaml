# Training configuration for all encoder types
# Run with: sbatch slurm/train_models.slurm

data:
  n_train: 50000
  n_val: 5000
  trajectory_length: 200
  alpha_range: [0.1, 2.0]
  D0_range: [0.1, 10.0]
  seed: 42

training:
  epochs: 50
  batch_size: 128
  lr: 0.001
  weight_decay: 0.0001
  num_workers: 4

# Each model: encoder + loss combination
models:
  # Simplest baseline
  linear:
    enabled: true
    encoder: linear
    loss: supervised
    seq_len: 200
    output_dim: 64
  
  # MLP baseline
  mlp:
    enabled: true
    encoder: mlp
    loss: supervised
    seq_len: 200
    hidden_dim: 256
    num_layers: 3
    output_dim: 64
    dropout: 0.1
  
  # LSTM (sequential patterns)
  lstm:
    enabled: true
    encoder: lstm
    loss: supervised
    hidden_dim: 64
    num_layers: 2
    dropout: 0.1
    bidirectional: true
  
  # CNN (multi-scale local patterns)
  cnn:
    enabled: true
    encoder: cnn
    loss: supervised
    channels: 32
    dropout: 0.1
  
  # Hybrid encoder (CNN + LSTM)
  hybrid:
    enabled: true
    encoder: hybrid
    loss: supervised
    hidden_dim: 64
    cnn_channels: 32
    dropout: 0.1
  
  # Hybrid + Physics loss (this is what makes it a "PINN")
  hybrid_pinn:
    enabled: true
    encoder: hybrid
    loss: combined
    hidden_dim: 64
    cnn_channels: 32
    dropout: 0.1
    lambda_physics: 0.1

output:
  dir: outputs/trained_models
