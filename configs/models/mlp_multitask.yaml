# =============================================================================
# Model: MLP Encoder - Multi-Task (Task 1 + Task 2)
# =============================================================================
# Simple MLP baseline for both α inference and model classification.
#
# Run: sbatch slurm/submit.slurm train configs/models/mlp_multitask.yaml
# =============================================================================

experiment:
  name: mlp-multitask
  description: Multi-task MLP for α inference + model classification

wandb:
  enabled: true
  project: anomalous-diffusion
  entity: taj_gillin-Brown University
  tags: [mlp, baseline, multitask, andi-challenge, task1, task2]
  notes: Multi-task learning baseline with MLP encoder

data:
  repo_id: taj-gillin/andi-trajectory
  train_split: train
  val_split: validation
  n_train: 50000
  n_val: 5000
  alpha_range: [0.1, 2.0]
  length_range: [50, 1000]
  pad_to_length: 1000
  seed: 42

model:
  encoder: mlp
  tasks: [alpha, model]
  loss: multitask
  loss_params:
    lambda_alpha: 1.0
    lambda_model: 1.0
  params:
    hidden_dim: 256
    num_layers: 3
    dropout: 0.2

training:
  epochs: 200
  batch_size: 128
  lr: 0.001
  weight_decay: 0.0001
  scheduler:
    warmup_epochs: 5
    min_lr_factor: 0.01
  num_workers: 4
  log_interval: 10
  early_stopping:
    enabled: false
    patience: 10
    min_delta: 0.0001

env:
  device: auto
  seed: 42
  deterministic: false
